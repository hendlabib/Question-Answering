{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping Data from Facebook posts using selenium!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing  all we need for scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-28e8abff976d>:6: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chromepath)\n"
     ]
    }
   ],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "\n",
    "chromepath = r\"C:\\Users\\3com\\Downloads\\chromedriver_win32\\chromedriver.exe\"\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=chromepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://web.facebook.com/?_rdc=1&_rdr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At the first we need to log in the facebook to can access the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping Started!\n"
     ]
    }
   ],
   "source": [
    "def login():\n",
    "\n",
    "    driver.get(\"https://web.facebook.com/?_rdc=1&_rdr\")\n",
    "    time.sleep(3)\n",
    "    driver.find_element(\"id\",\"email\").send_keys(\"email\")\n",
    "    time.sleep(1)\n",
    "    driver.find_element(\"id\",\"pass\").send_keys(\"pass\")\n",
    "    time.sleep(1)\n",
    "    driver.find_element(\"name\",\"login\").click()\n",
    "    time.sleep(4)\n",
    "\n",
    "print(\"Scrapping Started!\")\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File contains urls of posts that we need to scrapping it ...\n",
    "#### Now we can scrap !! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping Completed \n"
     ]
    }
   ],
   "source": [
    "file = open(\"postUrl.txt\",\"r\")\n",
    "lines = file.readlines()\n",
    "count = 0\n",
    "for line in lines:\n",
    "    count+=1\n",
    "    driver.get(line)\n",
    "    time.sleep(7)\n",
    "    post = driver.find_element(\"xpath\",\"//div[@role='article' and @aria-posinset='1']\")\n",
    "    auth=post.find_element(By.TAG_NAME, \"h3\")\n",
    "    fileName = 'Post'+str(count)+'.csv'\n",
    "    with open(fileName,'w',newline='',encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        writer.writerow([\"Author\",\"Description\"])\n",
    "        \n",
    "        author = auth.text\n",
    "        description=''\n",
    "        try:\n",
    "            description = post.find_element( \"css selector\",\"div[class='x1cy8zhl x78zum5 x1nhvcw1 x1n2onr6 xh8yej3']\").text\n",
    "        \n",
    "        except:\n",
    "            description =''\n",
    "            writer.writerow([author,description])\n",
    "            writer.writerow([\"\",\"\"])\n",
    "        while True:\n",
    "            try:             \n",
    "                driver.find_element(\"xpath\",\"//span[contains(text(),'View') and contains(text(),'comment')]\").click()\n",
    "                time.sleep(6)\n",
    "            except:\n",
    "                break\n",
    "        viewMore = post.find_elements(\"xpath\",\".//*[contains(text(),'View') and contains(text(),'more answers')]\")\n",
    "        for node in viewMore:\n",
    "            try:\n",
    "                node.click()\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                pass\n",
    "        replies = post.find_elements(\"xpath\",\".//*[contains(text(),'Reply') or contains(text(),'Replies')]\")\n",
    "        for node in replies:\n",
    "            try:\n",
    "                node.click()\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                pass\n",
    "        seeMore = post.find_elements(\"xpath\",\".//*[contains(text(),'see more')]\")\n",
    "        for node in seeMore:\n",
    "            try:\n",
    "                node.click()\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                pass\n",
    "        totalComments = post.find_elements('css selector','div[class=\"x1y1aw1k xn6708d xwib8y2 x1ye3gou\"]')\n",
    "        for comment in totalComments:\n",
    "            commentBy=comment.find_element(\"xpath\",\".//span/span[@dir='auto']\").text\n",
    "            commentDescription=''\n",
    "            try:\n",
    "                commentss = comment.find_elements(\"css selector\",\"div[class='x11i5rnm xat24cr x1mh8g0r x1vvkbs xdj266r']\")\n",
    "                \n",
    "                for cmt in commentss:\n",
    "                    commentDescription+= ' '+cmt.text.replace(\"\",\"\")\n",
    "            except:\n",
    "                commentDescription=''\n",
    "            writer.writerow([commentBy,commentDescription])\n",
    "            writer.writerow(['',''])\n",
    "print(\"Scrapping Completed \")\n",
    "                \n",
    "                     \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
